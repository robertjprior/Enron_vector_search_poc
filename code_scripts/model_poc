#%%
import re
import nltk
## for plotting
import matplotlib.pyplot as plt
#import seaborn as sns
## for w2v
import gensim
import gensim.downloader as gensim_api
## for bert
import transformers

import pandas as pd
import numpy as np
from sklearn import metrics, manifold
import timeit



#%%
df = pd.read_csv("../data/emails_clean.csv")
df = df.sample(n=1000, random_state=1)

# %% [markdown]
#LDA




# %% [markdown]
#Unlabeled CLassification


# %%
nlp = gensim_api.load("glove-wiki-gigaword-300")
# %%
## Function to apply
def get_similar_words(lst_words, top, nlp):
    lst_out = lst_words
    for tupla in nlp.most_similar(lst_words, topn=top):
        lst_out.append(tupla[0])
    return list(set(lst_out))
## Create Dictionary {category:[keywords]}
dic_clusters = {}
dic_clusters["fraud"] = get_similar_words(['fraud','cover-up','illegal','hide'], 
                  top=30, nlp=nlp)
# %%
from transformers import TFBertModel
from transformers import BertTokenizer

#%%
tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, use_fast=True)
nlp = TFBertModel.from_pretrained('bert-base-uncased')
# %%
## function to apply
start = timeit.default_timer()
def utils_bert_embedding(txt, tokenizer, nlp):
    idx = tokenizer.encode(txt, max_length=512)
    idx = np.array(idx)[None,:]  
    embedding = nlp(idx)
    X = np.array(embedding[0][0][1:-1])
    return X


#%%
lst_mean_vecs = [utils_bert_embedding(txt, tokenizer, nlp).mean(0) for txt in df["body"]]

X = np.array(lst_mean_vecs)
y = {k:utils_bert_embedding(v, tokenizer, nlp).mean(0) for k,v
         in dic_clusters.items()}['fraud']
#put the dic_cluster as the sort of target we will measure cosine similarity against

stop = timeit.default_timer()
print('Time in seconds: ', stop - start) 

#%%
#measure the cosine similarity and once for each obs
X = np.nan_to_num(X)
similarities = metrics.pairwise.cosine_similarity(X, y.reshape(1,-1))
pd.DataFrame(similarities).describe()
#%%
#graph the ratings and find an intuitive cutoff value
plt.hist(similarities, 50, density=True, facecolor='g', alpha=0.75)
plt.show()
# %%

# %%
